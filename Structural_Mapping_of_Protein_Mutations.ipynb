{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebbettin/UCH_SRL/blob/main/Structural_Mapping_of_Protein_Mutations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Structural Mapping of Protein Mutations**\n"
      ],
      "metadata": {
        "id": "PR4QxxlquItM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1. Install the required modules"
      ],
      "metadata": {
        "id": "piAQ-NHJuoIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython"
      ],
      "metadata": {
        "id": "GtCiNMVeNjw-",
        "outputId": "113920f0-d4e6-4628-ef69-0be9fae4dc49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n",
            "Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython\n",
            "Successfully installed biopython-1.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlsxwriter"
      ],
      "metadata": {
        "id": "iqKkZqUguGWv",
        "outputId": "e7b6c1b4-8398-4eca-f28c-ac7edb79f6f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y clustalo"
      ],
      "metadata": {
        "id": "4Xw_YAEwuzxj",
        "outputId": "a47ef6c4-674c-46ea-aaab-05faf515459b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libargtable2-0\n",
            "The following NEW packages will be installed:\n",
            "  clustalo libargtable2-0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 273 kB of archives.\n",
            "After this operation, 694 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libargtable2-0 amd64 13-1.1 [14.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 clustalo amd64 1.2.4-7 [259 kB]\n",
            "Fetched 273 kB in 1s (308 kB/s)\n",
            "Selecting previously unselected package libargtable2-0.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../libargtable2-0_13-1.1_amd64.deb ...\n",
            "Unpacking libargtable2-0 (13-1.1) ...\n",
            "Selecting previously unselected package clustalo.\n",
            "Preparing to unpack .../clustalo_1.2.4-7_amd64.deb ...\n",
            "Unpacking clustalo (1.2.4-7) ...\n",
            "Setting up libargtable2-0 (13-1.1) ...\n",
            "Setting up clustalo (1.2.4-7) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from Bio import SeqIO\n",
        "from Bio import AlignIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.Align.Applications import ClustalOmegaCommandline\n",
        "import pandas as pd\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "from google.colab import files\n",
        "import shutil"
      ],
      "metadata": {
        "id": "P8BWZU9gakIF",
        "outputId": "fa08308e-a851-482a-f794-15e7b7da74b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/Bio/Application/__init__.py:39: BiopythonDeprecationWarning: The Bio.Application modules and modules relying on it have been deprecated.\n",
            "\n",
            "Due to the on going maintenance burden of keeping command line application\n",
            "wrappers up to date, we have decided to deprecate and eventually remove these\n",
            "modules.\n",
            "\n",
            "We instead now recommend building your command line and invoking it directly\n",
            "with the subprocess module.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If you want to import files from your google drive, execute the following command.**"
      ],
      "metadata": {
        "id": "jAGOt6_xvIv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KN1U9sWpmrqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2. Nucleotide Translation\n",
        "If you are starting your analysis from DNA sequences execute the following commands. **The reference sequence for conservation analysis must be placed as the first in the fasta file.**\n",
        "\n",
        "You can create a new directory in Google Colab folder or use your own Google drive directory.\n",
        "\n",
        "**If using colab folders, all the outputs will be inputs for the next steps (recommended):**\n",
        "\n",
        "Create a folder named \"nucseq\" in the content directory"
      ],
      "metadata": {
        "id": "cRoIbRlbvQwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace input_dir and output_dir as required.\n",
        "input_dir = \"/content/nucseq\"\n",
        "output_dir = \"/content/protseq\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "def translate_sequence(nucleotide_seq):\n",
        "    amino_acid_seq = nucleotide_seq.translate()\n",
        "    return amino_acid_seq\n",
        "\n",
        "for filename in os.listdir(input_dir):\n",
        "    input_path = os.path.join(input_dir, filename)\n",
        "    if os.path.isfile(input_path):  # Check if it's a file\n",
        "        nucleotide_seqs = SeqIO.parse(input_path, \"fasta\")\n",
        "\n",
        "        amino_acid_seqs = []\n",
        "        for seq_record in nucleotide_seqs:\n",
        "            amino_acid_seq = translate_sequence(seq_record.seq)\n",
        "            amino_acid_record = seq_record\n",
        "            amino_acid_record.seq = amino_acid_seq\n",
        "            amino_acid_seqs.append(amino_acid_record)\n",
        "            output_filename = os.path.splitext(filename)[0] + \"_prot.fasta\"\n",
        "        output_path = os.path.join(output_dir, output_filename)\n",
        "        SeqIO.write(amino_acid_seqs, output_path, \"fasta\")"
      ],
      "metadata": {
        "id": "KWVQXwEvaYFa",
        "outputId": "680a5a61-c758-4faf-a7b3-10107b8a8a33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/Bio/Seq.py:2879: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3. Protein Alignment\n",
        "This step will perform the protein alignment using the output from the first step. The code will identify, list and exclude from alignment, all the entries containing stop codons in the middle of the sequence. **The reference sequence for conservation analysis must be placed as the first in the fasta file (if not inserted in the previous step).**"
      ],
      "metadata": {
        "id": "jvH4crvYwVfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Replace input_dir and output_dir as required.\n",
        "input_dir = \"/content/protseq\"\n",
        "output_dir = \"/content/aln\"\n",
        "\n",
        "# create the output directory if it does not exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# iterate over all files in the input directory\n",
        "for file in os.listdir(input_dir):\n",
        "    # check if file is a fasta file\n",
        "    if file.endswith(\".fasta\"):\n",
        "        input_path = os.path.join(input_dir, file)\n",
        "        output_path = os.path.join(output_dir, file)\n",
        "\n",
        "        # filter out sequences containing stop codons before the last residue\n",
        "        sequences = []\n",
        "        excluded_sequences = []\n",
        "        for record in SeqIO.parse(input_path, \"fasta\"):\n",
        "            sequence = str(record.seq)\n",
        "            if \"*\" not in sequence[:-1]:  # check if the last residue is not a stop codon\n",
        "                sequences.append(record)\n",
        "            else:\n",
        "                excluded_sequences.append(record.id)\n",
        "\n",
        "        # run Clustal Omega for non-excluded sequences and wait for it to finish\n",
        "        SeqIO.write(sequences, input_path, \"fasta\")  # overwrite input file with non-excluded sequences\n",
        "        clustalomega_cline = ClustalOmegaCommandline(infile=input_path, outfile=output_path, auto=True)\n",
        "        stdout, stderr = clustalomega_cline()\n",
        "\n",
        "        # parse Clustal alignment and print summary\n",
        "        alignment = AlignIO.read(output_path, \"fasta\")\n",
        "        print(\"Alignment of {} sequences with length {} has been created. Excluded sequences: {}\".format(\n",
        "            len(alignment), alignment.get_alignment_length(), \", \".join(excluded_sequences)))\n"
      ],
      "metadata": {
        "id": "ELBaAwVUrY3J",
        "outputId": "bfe9d9d8-027c-4ed9-b34d-f38141bd60f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alignment of 1687 sequences with length 268 has been created. Excluded sequences: TPVMW082H0_TP0479, TPVMW709Z0_TP0479, GSPMW018L0_TP0479, TPVCN006D0_TP0479, TPVMW708X0_TP0479, TPVCN02410_TP0479, TPVMW122K0_TP0479, DRR213714_TP0479, DRR213718_TP0479, ERR3684459_TP0479, ERR3684461_TP0479, ERR3684496_TP0479, ERR4899210_TP0479, ERR4993349_TP0479, SRR14277312_TP0479, SRR14277317_TP0479, SRR14277335_TP0479, SRR14277357_TP0479, SRR14277361_TP0479, SRR14277369_TP0479, SRR14277393_TP0479, SRR15440102_TP0479, SRR15440110_TP0479, SRR15440115_TP0479, SRR15440121_TP0479, SRR15440129_TP0479, SRR15440315_TP0479, SRR15440410_TP0479, SRR15440476_TP0479, SRR8501166_TP0479, SRR18191910_TP0479, SRR18191945_TP0479, SRR21135091_TP0479, SRR21135101_TP0479, SRR21144433_TP0479, SRR21144443_TP0479, SRR24385952_TP0479, SRR24385953_TP0479, SRR24385954_TP0479, SRR24385966_TP0479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4. Generation of Attribute Files\n",
        "This step will create attribute files that can be read by Chimera allowing the structural mapping of each mutation found in the alignments. The first sequence in the alignment files will be set as the reference sequence for conservation analysis."
      ],
      "metadata": {
        "id": "Bk1TFnUu0Opm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the input and output folders\n",
        "input_dir = \"/content/aln\"\n",
        "output_dir = \"/content/attributes\"\n",
        "\n",
        "# create the output directory if it does not exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Step 2: Iterate over all the files in the input folder\n",
        "for file_name in os.listdir(input_dir):\n",
        "    if file_name.endswith(\".fasta\"):\n",
        "        input_file_path = os.path.join(input_dir, file_name)\n",
        "\n",
        "        # Step 3: Read the alignment file\n",
        "        alignment = AlignIO.read(input_file_path, \"fasta\")\n",
        "\n",
        "        # Step 4: Get the reference sequence\n",
        "        ref_seq = alignment[0].seq\n",
        "\n",
        "        # Step 5: Calculate the identity of each residue\n",
        "        output_file_name = os.path.splitext(file_name)[0] + \"_attributes.txt\"\n",
        "        output_file_path = os.path.join(output_dir, output_file_name)\n",
        "\n",
        "        with open(output_file_path, \"w\") as f:\n",
        "            # Write the attribute headers\n",
        "            f.write(\"attribute: resconservation\\n\")\n",
        "            f.write(\"recipient: residues\\n\")\n",
        "            for j, ref_aa in enumerate(ref_seq):\n",
        "                if ref_aa == \"-\":\n",
        "                    continue\n",
        "                conservation_count = 0\n",
        "                for record in alignment:\n",
        "                    seq = str(record.seq)\n",
        "                    aa = seq[j]\n",
        "                    if aa == \"-\":\n",
        "                        continue\n",
        "                    if record.id != alignment[0].id and aa == ref_aa:\n",
        "                        conservation_count += 1\n",
        "                conservation_percentage = (conservation_count / (len(alignment)-1)) * 100 if ref_aa != '-' else 0\n",
        "                residue_num = j + 1\n",
        "\n",
        "                # Write the attribute value for this residue\n",
        "                line = f\"\\t:{residue_num}.A\\t{conservation_percentage:.2f}\\n\"\n",
        "                f.write(line)\n",
        "\n",
        "        print(\"Attribute file generated: \", output_file_path)"
      ],
      "metadata": {
        "id": "VIoJI1lXcbvs",
        "outputId": "d34573ea-a8ff-4aab-b05a-6839bb7d22ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attribute file generated:  /content/attributes/TP0479_1727genomes_prot_attributes.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 5. Summary Table of identified mutations\n",
        "This step will create excel sheets describing the identified mutations for each alignment as also a file combining all the data."
      ],
      "metadata": {
        "id": "99WIBerq3jGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the input and output directories\n",
        "input_dir = \"/content/aln\"\n",
        "output_dir = \"/content/table\"\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Iterate through each file in the input directory\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.endswith(\".fasta\"):\n",
        "        # Load the multi sequence alignment file\n",
        "        alignment = AlignIO.read(os.path.join(input_dir, filename), \"fasta\")\n",
        "\n",
        "        # Create an empty dictionary to store the mutation information\n",
        "        mutations_dict = {}\n",
        "\n",
        "        # Iterate through each position in the alignment and compare the amino acid residue at that position in each sequence\n",
        "        for i in range(alignment.get_alignment_length()):\n",
        "            position = i + 1\n",
        "            residues = set(alignment[:, i])\n",
        "            if len(residues) == 1:\n",
        "                continue  # skip if all residues at the position are the same\n",
        "            wt_residue = alignment[0, i]\n",
        "            for j in range(1, len(alignment)):\n",
        "                if alignment[j, i] != wt_residue:\n",
        "                    mutation = f\"{wt_residue}{position}{alignment[j, i]}\"\n",
        "                    if mutation in mutations_dict:\n",
        "                        mutations_dict[mutation][\"count\"] += 1\n",
        "                        mutations_dict[mutation][\"sequences\"].append(alignment[j].id)\n",
        "                    else:\n",
        "                        mutations_dict[mutation] = {\n",
        "                            \"position\": position,\n",
        "                            \"wt_residue\": wt_residue,\n",
        "                            \"mut_residue\": alignment[j, i],\n",
        "                            \"count\": 1,\n",
        "                            \"sequences\": [alignment[j].id],\n",
        "                        }\n",
        "\n",
        "        # Convert the mutations dictionary to a Pandas DataFrame\n",
        "        df = pd.DataFrame(mutations_dict.values(), columns=[\"wt_residue\", \"position\", \"mut_residue\", \"count\", \"sequences\"])\n",
        "\n",
        "        # Add a percentage column to the DataFrame\n",
        "        total_count = df[\"count\"].sum()\n",
        "        df[\"percentage\"] = (df[\"count\"] / (len(alignment) - 1)) * 100\n",
        "\n",
        "        # Save the DataFrame to an Excel file in the output directory\n",
        "        output_filename = os.path.splitext(filename)[0] + \"_mutations.xlsx\"\n",
        "\n",
        "        # Create a Pandas Excel writer\n",
        "        writer = pd.ExcelWriter(os.path.join(output_dir, output_filename), engine=\"xlsxwriter\")\n",
        "\n",
        "        # Write the DataFrame to the Excel sheet\n",
        "        df.to_excel(writer, sheet_name=\"mutations\", index=False)\n",
        "\n",
        "        # Get the worksheet object\n",
        "        worksheet = writer.sheets[\"mutations\"]\n",
        "\n",
        "        # Write the sequence headers to the new column\n",
        "        sequences = df[\"sequences\"].tolist()\n",
        "        sequence_column = len(df.columns) + 1  # Next column after the last column of DataFrame\n",
        "        worksheet.write(0, sequence_column - 1, \"Sequences\")  # Write column header\n",
        "        for i, seq_list in enumerate(sequences):\n",
        "            worksheet.write_column(1, sequence_column - 1, seq_list)\n",
        "\n",
        "        # Close the Pandas Excel writer\n",
        "        writer.close()\n"
      ],
      "metadata": {
        "id": "Q1GhlfTijTwC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the input directory for the mutation Excel files\n",
        "input_dir = \"/content/table\"\n",
        "\n",
        "# Create a new Excel file and add the first sheet\n",
        "output_filename = \"combined_mutations.xlsx\"\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "\n",
        "# Iterate through each file in the input directory\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.endswith(\"_mutations.xlsx\"):\n",
        "        # Load the Excel file into a Pandas DataFrame\n",
        "        df = pd.read_excel(os.path.join(input_dir, filename))\n",
        "\n",
        "        # Add a new sheet to the output file with the mutations from this input file\n",
        "        ws = wb.create_sheet(title=os.path.splitext(filename)[0])\n",
        "\n",
        "        # Write the mutations DataFrame to the new sheet\n",
        "        for r in dataframe_to_rows(df, index=False, header=True):\n",
        "            ws.append(r)\n",
        "\n",
        "# Save the output file\n",
        "wb.save(os.path.join(input_dir, output_filename))"
      ],
      "metadata": {
        "id": "NOGS0XDElX0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 6. Folders Download\n",
        "This step will download all folders from google colab. You can run only the commands for the desired folders."
      ],
      "metadata": {
        "id": "SeNUbIZs4YTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Proteins Folder\n",
        "folder_protseq = \"/content/protseq\"\n",
        "shutil.make_archive(folder_protseq, 'zip', folder_protseq)\n",
        "files.download(f\"{folder_protseq}.zip\")"
      ],
      "metadata": {
        "id": "_HtXosWesyb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Alignment Folder\n",
        "folder_aln = \"/content/aln\"\n",
        "shutil.make_archive(folder_aln, 'zip', folder_aln)\n",
        "files.download(f\"{folder_aln}.zip\")"
      ],
      "metadata": {
        "id": "d2a_qL7Vjqn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Attributes Folder\n",
        "folder_attributes = \"/content/attributes\"\n",
        "shutil.make_archive(folder_attributes, 'zip', folder_attributes)\n",
        "files.download(f\"{folder_attributes}.zip\")"
      ],
      "metadata": {
        "id": "OBazBdajjwTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Excel Sheet Folder\n",
        "folder_xlsx = \"/content/table\"\n",
        "shutil.make_archive(folder_xlsx, 'zip', folder_xlsx)\n",
        "files.download(f\"{folder_xlsx}.zip\")"
      ],
      "metadata": {
        "id": "jE_NRMkWj1CE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}